{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "# Graph imports\n",
    "import src.graph as graph\n",
    "import src.estimator as estimator\n",
    "import src.utils as utils\n",
    "\n",
    "# usual imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta should be higher than c\n",
    "n = 100 # number of nodes - 585 similar to c elegans\n",
    "p = 0  # number of neighbouts to take into account\n",
    "\n",
    "alpha = -0.03    #  negative 0.003\n",
    "beta  = -0.04    #  negative the higher the more concentrated will be the edges into a single vertex 0.003\n",
    "sigma = np.log(1/1e-2 - 1)    # intercept the higher the harder for creating edges 6\n",
    "\n",
    "threshold   = 0.5\n",
    "n_iteration = 10\n",
    "warm_up     = 5\n",
    "\n",
    "################################################\n",
    "params_dict = {\n",
    "    \"n\": n,\n",
    "    \"p\": p,\n",
    "    \"alpha\": alpha,\n",
    "    \"beta\": beta,\n",
    "    \"sigma\": sigma,\n",
    "    \"threshold\": threshold,\n",
    "    \"n_iteration\": n_iteration,\n",
    "    \"warm_up\": warm_up\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut  = utils.GraphUtils()\n",
    "\n",
    "graphs, spectra = ut.loading_graph_artifacts(params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation with MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = graphs[-1]\n",
    "s = spectra[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.plot_graph_from_adjacency(g, pos=None, title='Graph', size=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.plot_degree_distribution(g, title='Degree Distribution', size=(5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_guess = [0,0,0]\n",
    "est = estimator.MLEGraphModelEstimator(g)\n",
    "\n",
    "a_hat, b_hat, s_hat = est.estimate_parameters_torch(initial_guess=initial_guess, learning_rate=0.001, max_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_hat,b_hat,s_hat)\n",
    "print(alpha, beta, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = np.linspace(0.000001, 2, 100)\n",
    "beta_values = np.linspace(0.000001, 2, 100)\n",
    "\n",
    "likelihood = np.empty((len(c_values), len(beta_values)))\n",
    "for i, ci in enumerate(c_values):\n",
    "    for j, betaj in enumerate(beta_values):\n",
    "        likelihood[i, j] = est.likelihood_function([ci, betaj])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_history = np.array([initial_guess]+est.params_history)\n",
    "\n",
    "# Convert the parameters to the corresponding indices in the c_values and beta_values arrays\n",
    "c_indices = params_history[:, 0]\n",
    "beta_indices = params_history[:, 1]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot the full heatmap on the first subplot\n",
    "im = axs[0].imshow(likelihood, origin='lower', extent=[c_values[0], c_values[-1], beta_values[0], beta_values[-1]], aspect='auto')\n",
    "fig.colorbar(im, ax=axs[0], label='Likelihood')\n",
    "axs[0].scatter(c_indices, beta_indices, color='red', s=1)  # Change color as needed\n",
    "for i in range(1, len(c_indices)):\n",
    "    axs[0].arrow(c_indices[i-1], beta_indices[i-1], c_indices[i]-c_indices[i-1], beta_indices[i]-beta_indices[i-1], \n",
    "              shape='full', color='green', lw=1.5, length_includes_head=True, head_width=0.006)\n",
    "axs[0].set_xlabel('c')\n",
    "axs[0].set_ylabel('beta')\n",
    "axs[0].set_title('Likelihood function')\n",
    "\n",
    "# Plot a zoomed in region on the second subplot\n",
    "zoom_c_min, zoom_c_max = 0, 0.7  # Adjust these values to zoom in on the desired region\n",
    "zoom_beta_min, zoom_beta_max = 0, 1.1  # Adjust these values to zoom in on the desired region\n",
    "im_zoom = axs[1].imshow(likelihood, origin='lower', extent=[c_values[0], c_values[-1], beta_values[0], beta_values[-1]], aspect='auto')\n",
    "fig.colorbar(im_zoom, ax=axs[1], label='Likelihood')\n",
    "axs[1].scatter(c_indices, beta_indices, color='red', s=1)  # Change color as needed\n",
    "for i in range(1, len(c_indices)):\n",
    "    axs[1].arrow(c_indices[i-1], beta_indices[i-1], c_indices[i]-c_indices[i-1], beta_indices[i]-beta_indices[i-1], \n",
    "              shape='full', color='green', lw=1.5, length_includes_head=True, head_width=0.006)\n",
    "axs[1].set_xlim(zoom_c_min, zoom_c_max)\n",
    "axs[1].set_ylim(zoom_beta_min, zoom_beta_max)\n",
    "axs[1].set_xlabel('c')\n",
    "axs[1].set_ylabel('beta')\n",
    "axs[1].set_title('Zoomed in likelihood function')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation with regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta should be higher than c\n",
    "n = 500 # number of nodes - 585 similar to c elegans\n",
    "p = 0  # number of neighbouts to take into account\n",
    "\n",
    "alpha = -0.03    #  negative 0.003\n",
    "beta  = -0.04    #  negative the higher the more concentrated will be the edges into a single vertex 0.003\n",
    "sigma = np.log(1/1e-2 - 1)    # intercept the higher the harder for creating edges 6\n",
    "\n",
    "threshold   = 0.5\n",
    "n_iteration = 10\n",
    "warm_up     = 5\n",
    "\n",
    "################################################\n",
    "params_dict = {\n",
    "    \"n\": n,\n",
    "    \"p\": p,\n",
    "    \"alpha\": alpha,\n",
    "    \"beta\": beta,\n",
    "    \"sigma\": sigma,\n",
    "    \"threshold\": threshold,\n",
    "    \"n_iteration\": n_iteration,\n",
    "    \"warm_up\": warm_up\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_model = graph.GraphModel(n=n, p=p, alpha=alpha, beta=beta, sigma=sigma, threshold=threshold, n_iteration=n_iteration, warm_up=warm_up)\n",
    "graphs, spec = graph_model.populate_edges( warm_up = warm_up, max_iterations = n_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = graphs[-1]\n",
    "s = spec[-1]\n",
    "G = nx.Graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = estimator.LogitRegEstimator2(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, pvalue = est.estimate_parameters()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 1\n",
    "params_list = []\n",
    "for i in range(n_runs):\n",
    "    graph_model = graph.GraphModel(n=n, p=p, alpha=alpha, beta=beta, sigma=sigma, threshold=threshold, n_iteration=n_iteration, warm_up=warm_up)\n",
    "    graphs, _ = graph_model.populate_edges( warm_up = warm_up, max_iterations = n_iteration)\n",
    "    g = graphs[-1]\n",
    "    import gc\n",
    "    del graphs\n",
    "    gc.collect\n",
    "\n",
    "    est = estimator.LogitRegEstimator2(g)\n",
    "    params, pvalue = est.estimate_parameters()\n",
    "    params_list.append(params)\n",
    "\n",
    "    import pickle\n",
    "    with open('runs/results_array.pkl', 'wb') as f:\n",
    "        pickle.dump(params_list, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
